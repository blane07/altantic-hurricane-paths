{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/USA_zones.png)\n",
    "<center>(Figure 1) Impact Zones</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storm Status Codes**\n",
    "* WV - Tropical Wave\n",
    "* TD - Tropical Depression\n",
    "* TS - Tropical Storm\n",
    "* HU - Hurricane\n",
    "* EX - Extratropical cyclone\n",
    "* SD - Subtropical depression (winds <34 kt)\n",
    "* SS - Subtropical storm (winds >34 kt)\n",
    "* LO - A low pressure system not fitting any of above descriptions\n",
    "* DB - non-tropical Disturbance not have a closed circulation\n",
    "\n",
    "\"Storm Event Chain\" refers to the measurements of a particular storm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/hurdat2.csv', 'r') as f:\n",
    "    file_data = [row.strip().split(',') for row in f]\n",
    "df = pd.DataFrame(file_data)\n",
    "df.drop([2] + list(range(7,21)), axis='columns', inplace=True)\n",
    "cols = ['date', 'time', 'status', 'lat', 'lon', 'max_wind']\n",
    "data = pd.DataFrame(np.matrix(df), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lon_convert(lon):\n",
    "    lon = lon.strip()\n",
    "    lon_sign = 1\n",
    "    if lon[-1] == 'W':\n",
    "        lon_sign = -1\n",
    "    return lon_sign * float(lon[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_filter(t):\n",
    "    try:\n",
    "        int(t)\n",
    "        return(t)\n",
    "    except:\n",
    "        return('9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(time_str):\n",
    "    try:\n",
    "        return(int(time_str.strip()))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date = data.date.apply(lambda x: '99999999' if x[0] == 'A' else x.strip())\n",
    "data.time = data.time.apply(lambda x: x.strip())\n",
    "data.status = data.status.apply(lambda x: 'NE' if x == '' else x.strip())\n",
    "data.lat = data.lat.apply(lambda x: '00.0N' if x is None else x.strip())\n",
    "data.lat = data.lat.apply(lambda x: float(x.strip()[:-1]))\n",
    "data.lon = data.lon.apply(lambda x: '00.0W' if x is None else x.strip())\n",
    "data.lon = data.lon.apply(lambda x: lon_convert(x))\n",
    "data = data[data.lon > -200]    # Dropping noise\n",
    "data.max_wind = data.max_wind.apply(lambda x: 0 if x is None else int(x.strip()))\n",
    "data.time = data.time.apply(lambda x: time_filter(x))\n",
    "data.loc[:, 'year'] = data.date.apply(lambda x: int(x[0:4]))\n",
    "data.loc[:, 'month'] = data.date.apply(lambda x: int(x[4:6]))\n",
    "data.loc[:, 'day'] = data.date.apply(lambda x: int(x[6:8]))\n",
    "data.drop('date', axis='columns', inplace=True)\n",
    "data.loc[:, 'hour'] = data.time.apply(lambda x: int(x[0:2]))\n",
    "data.loc[:, 'minute'] = data.time.apply(lambda x: int(x[2:4]))\n",
    "data.drop(['time', 'minute'], axis='columns', inplace=True)\n",
    "data.max_wind = data.max_wind.apply(lambda x: 30 if x == -99 else x)\n",
    "data.loc[:, 'td'] = data.hour.diff()    # Time delta\n",
    "data.td = data.td.apply(lambda x: x + 24 if x < 0 else x)\n",
    "data.td = data.td.apply(lambda x: 6 if x < 0 else x)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Hurricane Harvey and Irma data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU_2017 = pd.read_csv('./data/hurricanes_2017.csv')\n",
    "HU_2017.lon = HU_2017.lon.apply(lambda x: -x)\n",
    "data = pd.concat([data, HU_2017]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign zones according to measurement's latitude and longitude (see figure 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lat_lon'] = list(zip(data.lat, data.lon))\n",
    "data.loc[:, 'A'] = data.lat_lon.apply(lambda x: 1 if (28.0 > x[0] >= 25.9) & \n",
    "                                      (-99.1 < x[1] <= -95.9) else 0)\n",
    "data.loc[:, 'B'] = data.lat_lon.apply(lambda x: 1 if (30.9 > x[0] >= 28.0) & \n",
    "                                      (-97.6 < x[1] <= -92.4) else 0)\n",
    "data.loc[:, 'C'] = data.lat_lon.apply(lambda x: 1 if (31.2 > x[0] >= 28.9) & \n",
    "                                      (-92.4 < x[1] <= -88.5) else 0)\n",
    "data.loc[:, 'D'] = data.lat_lon.apply(lambda x: 1 if (31.4 > x[0] >= 28.9) & \n",
    "                                      (-88.5 < x[1] <= -85.1) else 0)\n",
    "data.loc[:, 'E'] = data.lat_lon.apply(lambda x: 1 if (31.2 > x[0] >= 28.9) & \n",
    "                                      (-85.0 < x[1] <= -79.9) else 0)\n",
    "data.loc[:, 'F'] = data.lat_lon.apply(lambda x: 1 if (28.9 > x[0] >= 26.7) & \n",
    "                                      (-83.3 < x[1] <= -80.0) else 0)\n",
    "data.loc[:, 'G'] = data.lat_lon.apply(lambda x: 1 if (26.7 > x[0] >= 24.4) & \n",
    "                                      (-82.6 < x[1] <= -79.0) else 0)\n",
    "data.loc[:, 'H'] = data.lat_lon.apply(lambda x: 1 if (34.0 > x[0] >= 31.2) & \n",
    "                                      (-82.4 < x[1] <= -78.3) else 0)\n",
    "data.loc[:, 'I'] = data.lat_lon.apply(lambda x: 1 if (37.4 > x[0] >= 34.0) & \n",
    "                                      (-80.7 < x[1] <= -75.4) else 0)\n",
    "data.loc[:, 'J'] = data.lat_lon.apply(lambda x: 1 if (41.6 > x[0] >= 37.4) & \n",
    "                                      (-78.8 < x[1] <= -72.0) else 0)\n",
    "data.loc[:, 'K'] = data.lat_lon.apply(lambda x: 1 if (45.4 > x[0] >= 40.7) & \n",
    "                                      (-72.0 < x[1] <= -67.5) else 0)\n",
    "data.drop(['lat_lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any double-dipping between zones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data.A + data.B + data.C + data.D + data.E + data.F + data.G + data.H + data.I + \\\n",
    "      data.J + data.K) > 1].count().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/hurdat2_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of 'New Event' events. This will serve as a point for the beginning of each storm event chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []\n",
    "events_index = np.array(data[data.status == 'NE'].index)\n",
    "for i in range(1, 1832):\n",
    "    num.append(events_index[i] - events_index[i - 1])\n",
    "num += [51]    # Last storm event in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of prior measurements feature for each measurement in a storm event chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_meas = []\n",
    "temp = num\n",
    "for i in data.index:\n",
    "    if data.status[i] == 'NE':\n",
    "        count = num[0]\n",
    "        sub_count = count\n",
    "        del temp[0]\n",
    "    else:\n",
    "        sub_count -= 1\n",
    "    num_meas.append(count - sub_count)\n",
    "data.loc[:, 'prior_measures'] = num_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each measurement is assigned a impact zone values based the storm's future, present, or past zone impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_update = []\n",
    "counter = 0\n",
    "while counter < 51571:\n",
    "    if data.status[counter] == 'NE':\n",
    "        counter += 1\n",
    "        stop = 0\n",
    "        stat_ary = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        while data.status[counter] != 'NE' or stop > 150:\n",
    "            stat_ary += np.array(data[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "                                       'I', 'J', 'K']].iloc[counter])\n",
    "            counter += 1\n",
    "            stop += 1\n",
    "    else:\n",
    "        print('***************', list(data.iloc[counter]))\n",
    "        counter += 1\n",
    "    status_update.append([counter, np.sign(stat_ary)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating dataframe with impact zone information for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raven/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "status_mat = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "for _ in range(status_update[0][0] - 1):\n",
    "    status_mat = np.vstack((status_mat, status_update[0][1]))\n",
    "for i in range(1, len(status_update)):\n",
    "    for _ in range(status_update[i][0] - status_update[i-1][0]):\n",
    "        status_mat = np.vstack((status_mat, status_update[i][1]))\n",
    "status_mat = np.vstack((status_mat, np.array(data[['A', 'B', 'C', 'D', 'E', 'F', 'G',\n",
    "                                                   'H', 'I', 'J', 'K']].iloc[51572:])))\n",
    "data[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']] = status_mat\n",
    "data.iloc[51573:].A = data.iloc[51573:].A.apply(lambda x: 1)\n",
    "data.iloc[51573:].B = data.iloc[51573:].B.apply(lambda x: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding previous 7 measurements for each measurement (lagged features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['status'], prefix_sep='')\n",
    "cols = ['lat', 'lon', 'max_wind', 'td', 'statusDB', 'statusEX', 'statusHU', 'statusLO',\n",
    "        'statusNE', 'statusSD', 'statusSS', 'statusTD', 'statusTS', 'statusWV']\n",
    "data = pd.concat([data,\n",
    "                  data[cols].shift(-1),\n",
    "                  data[cols].shift(-2),\n",
    "                  data[cols].shift(-3),\n",
    "                  data[cols].shift(-4),\n",
    "                  data[cols].shift(-5),\n",
    "                  data[cols].shift(-6),\n",
    "                  data[cols].shift(-7)],\n",
    "                 axis=1).iloc[:-7]    # Drop NaN rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['lat', 'lon', 'max_wind', 'year', 'month', 'day', 'hour',\n",
    "       'td', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "       'I', 'J', 'K', 'prior_measures', 'statusDB', 'statusEX', 'statusHU',\n",
    "       'statusLO', 'statusNE', 'statusSD', 'statusSS', 'statusTD', 'statusTS',\n",
    "       'statusWV', 'lat1', 'lon1', 'max_wind1', 'td1', 'statusDB1',\n",
    "       'statusEX1', 'statusHU1', 'statusLO1', 'statusNE1', 'statusSD1', 'statusSS1',\n",
    "       'statusTD1', 'statusTS1', 'statusWV1', 'lat2', 'lon2', 'max_wind2',\n",
    "       'td2', 'statusDB2', 'statusEX2', 'statusHU2', 'statusLO2', 'statusNE2',\n",
    "       'statusSD2', 'statusSS2', 'statusTD2', 'statusTS2', 'statusWV2',\n",
    "       'lat3', 'lon3', 'max_wind3', 'td3', 'statusDB3', 'statusEX3',\n",
    "       'statusHU3', 'statusLO3', 'statusNE3', 'statusSD3', 'statusSS3', 'statusTD3',\n",
    "       'statusTS3', 'statusWV3', 'lat4', 'lon4', 'max_wind4', 'td4',\n",
    "       'statusDB4', 'statusEX4', 'statusHU4', 'statusLO4', 'statusNE4', 'statusSD4',\n",
    "       'statusSS4', 'statusTD4', 'statusTS4', 'statusWV4', 'lat5', 'lon5',\n",
    "       'max_wind5', 'td5', 'statusDB5', 'statusEX5', 'statusHU5', 'statusLO5',\n",
    "       'statusNE5', 'statusSD5', 'statusSS5', 'statusTD5', 'statusTS5', 'statusWV5',\n",
    "       'lat6', 'lon6', 'max_wind6', 'td6', 'statusDB6', 'statusEX6',\n",
    "       'statusHU6', 'statusLO6', 'statusNE6', 'statusSD6', 'statusSS6', 'statusTD6',\n",
    "       'statusTS6', 'statusWV6', 'lat7', 'lon7', 'max_wind7', 'td7',\n",
    "       'statusDB7', 'statusEX7', 'statusHU7', 'statusLO7', 'statusNE7', 'statusSD7',\n",
    "       'statusSS7', 'statusTD7', 'statusTS7', 'statusWV7']\n",
    "data.drop(['statusNE', 'statusNE1', 'statusNE2', 'statusNE3', 'statusNE4', 'statusNE5',\n",
    "           'statusNE6', 'statusNE7'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out 'New Event' rows (no longer needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.month != 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['year', 'month', 'day', 'hour'], prefix_sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out measurements that do not have at least seven lagged measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.prior_measures >= 8]\n",
    "data.drop(['prior_measures'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 'index' column (not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/hurdat2_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
